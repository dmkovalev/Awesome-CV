% This file was created with JabRef 2.10.
% Encoding: UTF8


@Article{Akil2011,
  Title                    = {Challenges and opportunities in mining neuroscience data},
  Author                   = {Akil, Huda and Martone, Maryann E and Van Essen, David C},
  Journal                  = {Science (New York, NY)},
  Year                     = {2011},
  Number                   = {6018},
  Pages                    = {708},
  Volume                   = {331},

  Keywords                 = {challenges},
  Owner                    = {IPI},
  Publisher                = {NIH Public Access},
  Timestamp                = {2014.10.28}
}

@Article{Bell2009,
  Title                    = {Beyond the data deluge},
  Author                   = {Bell, Gordon and Hey, Tony and Szalay, Alex},
  Journal                  = {Science},
  Year                     = {2009},
  Number                   = {5919},
  Pages                    = {1297--1298},
  Volume                   = {323},

  Owner                    = {IPI},
  Timestamp                = {2015.03.03}
}

@Book{Council2013,
  Title                    = {Frontiers in Massive Data Analysis},
  Author                   = {National Research Council},
  Publisher                = {The National Academies Press},
  Year                     = {2013},

  Address                  = {Washington, DC},

  Abstract                 = {Data mining of massive data sets is transforming the way we think about crisis response, marketing, entertainment, cybersecurity and national intelligence. Collections of documents, images, videos, and networks are being thought of not merely as bit strings to be stored, indexed, and retrieved, but as potential sources of discovery and knowledge, requiring sophisticated analysis techniques that go far beyond classical indexing and keyword counting, aiming to find relational and semantic interpretations of the phenomena underlying the data. Frontiers in Massive Data Analysis examines the frontier of analyzing massive amounts of data, whether in a static database or streaming through a system. Data at that scale--terabytes and petabytes--is increasingly common in science (e.g., particle physics, remote sensing, genomics), Internet commerce, business analytics, national security, communications, and elsewhere. The tools that work to infer knowledge from data at smaller scales do not necessarily work, or work well, at such massive scale. New tools, skills, and approaches are necessary, and this report identifies many of them, plus promising research directions to explore. Frontiers in Massive Data Analysis discusses pitfalls in trying to infer knowledge from massive data, and it characterizes seven major classes of computation that are common in the analysis of massive data. Overall, this report illustrates the cross-disciplinary knowledge--from computer science, statistics, machine learning, and application disciplines--that must be brought to bear to make useful inferences from massive data.},
  Keywords                 = {challenges},
  Owner                    = {IPI},
  Timestamp                = {2014.10.28},
  Url                      = {http://www.nap.edu/catalog.php?record_id=18374}
}

@Article{Czekaj2014a,
  Title                    = {The Besancon Galaxy model renewed I. Constraints on the local star formation history from Tycho data},
  Author                   = {Czekaj, MA and Robin, AC and Figueras, F and Luri, X and Haywood, M},
  Journal                  = {arXiv preprint arXiv:1402.3257},
  Year                     = {2014},

  Month                    = feb,

  Abstract                 = {The understanding of Galaxy evolution can be facilitated by the use of population synthesis models, which allows us to test hypotheses on the star formation history, star evolution, and chemical and dynamical evolution of the Galaxy. The new version of the Besancon Galaxy model (hereafter BGM) aims to provide a more flexible and powerful tool to investigate the initial mass function (IMF) and star formation rate (SFR) of the Galactic disc. We present a new strategy for the generation of thin disc stars, which assumes the IMF, SFR and evolutionary tracks as free parameters. We have updated most of the ingredients for the star count production and, for the first time, binary stars are generated in a consistent way. The local dynamical self-consistency is maintained in this new scheme. We then compare simulations from the new model with Tycho-2 data and the local luminosity function, as a first test to verify and constrain the new ingredients. The effects of changing thirteen different ingredients of the model are systematically studied. For the first time, a full sky comparison is performed between BGM and data. This strategy allows us to constrain the IMF slope at high masses, which is found to be close to 3.0 and excludes a shallower slope such as Salpeter's one. The SFR is found decreasing whatever IMF is assumed. The model is compatible with a local dark matter density of 0.011 Mo/pc^3 implying that there is no compelling evidence for the significant amount of dark matter in the disc. While the model is fitted to Tycho-2 data, which is a magnitude limited sample with V<11, we check that it is still consistent with fainter stars. The new model constitutes a new basis for further comparisons with large scale surveys and is being prepared to become a powerful tool for the analysis of the Gaia mission data.},
  Comments                 = {accepted in Astronomy and Astrophysics, 20 pages, 16 figures},
  Eprint                   = {1402.3257},
  Keywords                 = {astronomy},
  Oai2identifier           = {1402.3257},
  Owner                    = {IPI},
  Timestamp                = {2014.10.28},
  Url                      = {http://arxiv.org/abs/1402.3257}
}

@Article{Duggan,
  Title                    = {Hephaestus: Data Reuse for Accelerating Scientific Discovery},
  Author                   = {Duggan, Jennie and Brodie, Michael L},
  Owner                    = {dmitry},
  Timestamp                = {2015.11.02}
}

@Article{Francisco2011,
  Title                    = {The Netezza data appliance architecture: a platform for high performance data warehousing and analytics},
  Author                   = {Francisco, Phil and others},
  Journal                  = {IBM Redbooks},
  Year                     = {2011},

  Owner                    = {IPI},
  Timestamp                = {2015.03.04}
}

@Article{Goncalves2014a,
  Title                    = {Managing large-scale scientific hypotheses as uncertain data with support for predictive analytics},
  Author                   = {Gon{\c{c}}alves, Bernardo and Porto, Fabio},
  Journal                  = {arXiv preprint arXiv:1405.5905},
  Year                     = {2014},

  Month                    = may,

  Abstract                 = {In the era of data-intensive science and big data, much of the scientific thinking has been shifting to the data analysis phase of the research life cycle. To meet this paradigm shift, the vision of $\Upsilon$-DB abstracts deterministic scientific hypotheses as a kind of uncertain data. It comprises a probabilistic database design methodology for the systematic construction and management of U-relational hypothesis databases, viz., $\Upsilon$-DBs. The methodology of $\Upsilon$-DB allows scientists and engineers to manage and evaluate (rate/rank) scientific hypotheses `as uncertain data.' In this paper we show the applicability of $\Upsilon$-DB in a real-world scenario. We present use cases in Computational Hemodynamics derived from the Physiome project.},
  Comments                 = {Conference submission},
  Eprint                   = {1405.5905},
  Oai2identifier           = {1405.5905},
  Owner                    = {IPI},
  Timestamp                = {2014.10.28},
  Url                      = {http://arxiv.org/abs/1405.5905}
}

@Book{Greenwald2011,
  Title                    = {Achieving extreme performance with Oracle Exadata},
  Author                   = {Greenwald, Rick and Bhuller, Mans and Stackowiak, Robert and Alam, Maqsood},
  Publisher                = {McGraw-Hill},
  Year                     = {2011},

  Owner                    = {IPI},
  Timestamp                = {2015.03.04}
}

@Article{Hillebrandt2014,
  Title                    = {Effective connectivity during animacy perception-dynamic causal modelling of Human Connectome Project data},
  Author                   = {Hillebrandt, Hauke and Friston, Karl J and Blakemore, Sarah-Jayne},
  Journal                  = {Scientific reports},
  Year                     = {2014},
  Volume                   = {4},

  Keywords                 = {connectome, DCM},
  Owner                    = {IPI},
  Publisher                = {Nature Publishing Group},
  Timestamp                = {2014.10.28}
}

@Article{Kogalovsky2009,
  Title                    = {Conceptual and ontological modeling in information systems},
  Author                   = {Kogalovsky, Mikhail R and Kalinichenko, Leonid A},
  Journal                  = {Programming and Computer Software},
  Year                     = {2009},
  Number                   = {5},
  Pages                    = {241--256},
  Volume                   = {35},

  __markedentry            = {[dmitry:]},
  Owner                    = {dmitry},
  Publisher                = {Springer},
  Timestamp                = {2015.11.02}
}

@Article{Lenartowicz2010,
  Title                    = {Towards an ontology of cognitive control},
  Author                   = {Lenartowicz, Agatha and Kalar, Donald J and Congdon, Eliza and Poldrack, Russell A},
  Journal                  = {Topics in Cognitive Science},
  Year                     = {2010},
  Number                   = {4},
  Pages                    = {678--692},
  Volume                   = {2},

  Owner                    = {IPI},
  Publisher                = {Wiley Online Library},
  Timestamp                = {2014.10.28}
}

@Article{Penny2010,
  Title                    = {Comparing families of dynamic causal models},
  Author                   = {Penny, Will D and Stephan, Klaas E and Daunizeau, Jean and Rosa, Maria J and Friston, Karl J and Schofield, Thomas M and Leff, Alex P},
  Journal                  = {PLoS computational biology},
  Year                     = {2010},
  Number                   = {3},
  Pages                    = {e1000709},
  Volume                   = {6},

  Keywords                 = {connectome, DCM},
  Owner                    = {IPI},
  Publisher                = {Public Library of Science},
  Timestamp                = {2014.10.28}
}

@Article{Poldrack2006,
  Title                    = {Can cognitive processes be inferred from neuroimaging data?},
  Author                   = {Poldrack, Russell A},
  Journal                  = {Trends in cognitive sciences},
  Year                     = {2006},
  Number                   = {2},
  Pages                    = {59--63},
  Volume                   = {10},

  Owner                    = {IPI},
  Publisher                = {Elsevier},
  Timestamp                = {2014.10.28},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1364661305003360}
}

@Article{Price2005,
  Title                    = {Functional ontologies for cognition: The systematic definition of structure and function},
  Author                   = {Price, Cathy J and Friston, Karl J},
  Journal                  = {Cognitive Neuropsychology},
  Year                     = {2005},
  Number                   = {3-4},
  Pages                    = {262--275},
  Volume                   = {22},

  Owner                    = {IPI},
  Publisher                = {Taylor \& Francis},
  Timestamp                = {2014.10.28},
  Url                      = {http://www.tandfonline.com/doi/abs/10.1080/02643290442000095}
}

@InCollection{Smith1982,
  Title                    = {Principles of database conceptual design},
  Author                   = {Smith, John Miles and Smith, Diane CP},
  Booktitle                = {Data Base Design Techniques I:},
  Publisher                = {Springer},
  Year                     = {1982},
  Pages                    = {114--146},

  __markedentry            = {[dmitry:6]},
  Owner                    = {dmitry},
  Timestamp                = {2015.11.03}
}

@Article{Sporns2013,
  Title                    = {The human connectome: origins and challenges},
  Author                   = {Sporns, Olaf},
  Journal                  = {Neuroimage},
  Year                     = {2013},
  Pages                    = {53--61},
  Volume                   = {80},

  Owner                    = {IPI},
  Publisher                = {Elsevier},
  Timestamp                = {2014.10.28},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1053811913002656}
}

@Book{Sporns2012,
  Title                    = {Discovering the human connectome},
  Author                   = {Sporns, Olaf},
  Publisher                = {MIT Press},
  Year                     = {2012},

  Keywords                 = {connectome},
  Owner                    = {IPI},
  Timestamp                = {2014.10.28}
}

@Article{Stephan2010,
  Title                    = {Ten simple rules for dynamic causal modeling},
  Author                   = {Stephan, Klaas Enno and Penny, Will D and Moran, Rosalyn J and den Ouden, Hanneke EM and Daunizeau, Jean and Friston, Karl J},
  Journal                  = {Neuroimage},
  Year                     = {2010},
  Number                   = {4},
  Pages                    = {3099--3109},
  Volume                   = {49},

  Keywords                 = {connectome, DCM},
  Owner                    = {IPI},
  Publisher                = {Elsevier},
  Timestamp                = {2014.10.28},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1053811909011999}
}

@Book{Hey2009,
  Title                    = {The fourth paradigm: data-intensive scientific discovery},
  Editor                   = {Hey, Anthony JG and Tansley, Stewart and Tolle, Kristin Michele and others},
  Publisher                = {Microsoft Research Redmond, WA},
  Year                     = {2009},

  Keywords                 = {challenges},
  Owner                    = {IPI},
  Timestamp                = {2014.10.28}
}

